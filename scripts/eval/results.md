Printing gauntlet results for all models
| model_name                                    |   average |   world_knowledge |   commonsense_reasoning |   language_understanding |   symbolic_problem_solving |   reading_comprehension |
|:----------------------------------------------|----------:|------------------:|------------------------:|-------------------------:|---------------------------:|------------------------:|
| tiiuae/falcon-7b                              |  0.303717 |          0.278825 |                0.418959 |                 0.368529 |                   0.139765 |                0.312509 |
| mosaicml/mpt-7b-instruct                      |  0.273064 |          0.339565 |                0.384446 |                 0.370156 |                   0.156427 |                0.114725 |
| togethercomputer/RedPajama-INCITE-7B-Instruct |  0.265547 |          0.313713 |                0.353561 |                 0.352964 |                   0.204133 |                0.103363 |
| mosaicml/mpt-7b                               |  0.261089 |          0.309635 |                0.366361 |                 0.379669 |                   0.14823  |                0.101552 |
| togethercomputer/RedPajama-INCITE-7B-Base |  0.235482 |          0.307123 |                0.337767 |                 0.368699 |                   0.117491 |               0.0463286 |
Printing complete results for all models
| Category                 | Benchmark                        | Subtask                             |    Accuracy |   Number few shot | Model                                         |
|:-------------------------|:---------------------------------|:------------------------------------|------------:|------------------:|:----------------------------------------------|
| commonsense_reasoning    | copa                             |                                     | 0.84        |                 0 | tiiuae/falcon-7b                              |
| commonsense_reasoning    | piqa                             |                                     | 0.799782    |                 0 | tiiuae/falcon-7b                              |
| commonsense_reasoning    | bigbench_strategy_qa             |                                     | 0.56007     |                 0 | tiiuae/falcon-7b                              |
| commonsense_reasoning    | piqa                             |                                     | 0.807943    |                10 | tiiuae/falcon-7b                              |
| commonsense_reasoning    | bigbench_strange_stories         |                                     | 0.706897    |                10 | tiiuae/falcon-7b                              |
| commonsense_reasoning    | bigbench_strategy_qa             |                                     | 0.597204    |                10 | tiiuae/falcon-7b                              |
| commonsense_reasoning    | bigbench_novel_concepts          |                                     | 0.53125     |                10 | tiiuae/falcon-7b                              |
| commonsense_reasoning    | bigbench_strange_stories         |                                     | 0.586207    |                 0 | tiiuae/falcon-7b                              |
| commonsense_reasoning    | bigbench_novel_concepts          |                                     | 0.375       |                 0 | tiiuae/falcon-7b                              |
| commonsense_reasoning    | openbook_qa                      |                                     | 0.426       |                 0 | tiiuae/falcon-7b                              |
| language_understanding   | hellaswag                        |                                     | 0.775742    |                10 | tiiuae/falcon-7b                              |
| language_understanding   | bigbench_language_identification |                                     | 0.2564      |                10 | tiiuae/falcon-7b                              |
| language_understanding   | bigbench_conceptual_combinations |                                     | 0.262136    |                10 | tiiuae/falcon-7b                              |
| language_understanding   | bigbench_conlang_translation     |                                     | 0.0670732   |                 0 | tiiuae/falcon-7b                              |
| language_understanding   | lambada_openai                   |                                     | 0.746555    |                 0 | tiiuae/falcon-7b                              |
| language_understanding   | hellaswag                        |                                     | 0.771759    |                 0 | tiiuae/falcon-7b                              |
| language_understanding   | winograd                         |                                     | 0.846154    |                 0 | tiiuae/falcon-7b                              |
| language_understanding   | bigbench_conceptual_combinations |                                     | 0.320388    |                 0 | tiiuae/falcon-7b                              |
| language_understanding   | bigbench_language_identification |                                     | 0.2517      |                 0 | tiiuae/falcon-7b                              |
| language_understanding   | bigbench_conlang_translation     |                                     | 0.0487805   |                10 | tiiuae/falcon-7b                              |
| language_understanding   | winogrande                       |                                     | 0.674033    |                 0 | tiiuae/falcon-7b                              |
| reading_comprehension    | squad                            |                                     | 0.000473037 |                 0 | tiiuae/falcon-7b                              |
| reading_comprehension    | bigbench_understanding_fables    |                                     | 0.248677    |                10 | tiiuae/falcon-7b                              |
| reading_comprehension    | bigbench_understanding_fables    |                                     | 0.259259    |                 0 | tiiuae/falcon-7b                              |
| reading_comprehension    | boolq                            |                                     | 0.737309    |                 0 | tiiuae/falcon-7b                              |
| reading_comprehension    | pubmed_qa_labeled                |                                     | 0.44        |                10 | tiiuae/falcon-7b                              |
| reading_comprehension    | squad                            |                                     | 0.426112    |                10 | tiiuae/falcon-7b                              |
| reading_comprehension    | coqa                             |                                     | 0.217462    |                10 | tiiuae/falcon-7b                              |
| reading_comprehension    | pubmed_qa_labeled                |                                     | 0           |                 0 | tiiuae/falcon-7b                              |
| reading_comprehension    | coqa                             |                                     | 0.00338219  |                 0 | tiiuae/falcon-7b                              |
| reading_comprehension    | boolq                            |                                     | 0.740367    |                10 | tiiuae/falcon-7b                              |
| symbolic_problem_solving | bigbench_elementary_math_qa      |                                     | 0.265487    |                10 | tiiuae/falcon-7b                              |
| symbolic_problem_solving | bigbench_operators               |                                     | 0.209524    |                 0 | tiiuae/falcon-7b                              |
| symbolic_problem_solving | bigbench_logical_deduction       |                                     | 0.251333    |                 0 | tiiuae/falcon-7b                              |
| symbolic_problem_solving | bigbench_cs_algorithms           |                                     | 0.0356061   |                 0 | tiiuae/falcon-7b                              |
| symbolic_problem_solving | bigbench_dyck_languages          |                                     | 0           |                 0 | tiiuae/falcon-7b                              |
| symbolic_problem_solving | bigbench_elementary_math_qa      |                                     | 0.273428    |                 0 | tiiuae/falcon-7b                              |
| symbolic_problem_solving | simple_arithmetic_withspaces     |                                     | 0.095       |                 0 | tiiuae/falcon-7b                              |
| symbolic_problem_solving | bigbench_dyck_languages          |                                     | 0.233       |                10 | tiiuae/falcon-7b                              |
| symbolic_problem_solving | bigbench_cs_algorithms           |                                     | 0.468939    |                10 | tiiuae/falcon-7b                              |
| symbolic_problem_solving | bigbench_repeat_copy_logic       |                                     | 0           |                 0 | tiiuae/falcon-7b                              |
| symbolic_problem_solving | bigbench_logical_deduction       |                                     | 0.245333    |                10 | tiiuae/falcon-7b                              |
| symbolic_problem_solving | bigbench_repeat_copy_logic       |                                     | 0.21875     |                10 | tiiuae/falcon-7b                              |
| symbolic_problem_solving | simple_arithmetic_nospaces       |                                     | 0.15        |                10 | tiiuae/falcon-7b                              |
| symbolic_problem_solving | simple_arithmetic_withspaces     |                                     | 0.003       |                10 | tiiuae/falcon-7b                              |
| symbolic_problem_solving | math_qa                          |                                     | 0.2588      |                10 | tiiuae/falcon-7b                              |
| symbolic_problem_solving | logi_qa                          |                                     | 0.25192     |                10 | tiiuae/falcon-7b                              |
| symbolic_problem_solving | math_qa                          |                                     | 0.259806    |                 0 | tiiuae/falcon-7b                              |
| symbolic_problem_solving | logi_qa                          |                                     | 0.225806    |                 0 | tiiuae/falcon-7b                              |
| symbolic_problem_solving | bigbench_operators               |                                     | 0.295238    |                10 | tiiuae/falcon-7b                              |
| symbolic_problem_solving | simple_arithmetic_nospaces       |                                     | 0.014       |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_psychology              | 0.227523    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_computer_science        | 0.27        |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_statistics              | 0.189815    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_us_history              | 0.269608    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_world_history           | 0.312236    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_physics                 | 0.258278    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_microeconomics          | 0.235294    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_computer_science        | 0.27        |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_macroeconomics          | 0.238462    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | college_medicine                    | 0.254335    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | college_physics                     | 0.264706    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | computer_security                   | 0.31        |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | conceptual_physics                  | 0.297872    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | econometrics                        | 0.245614    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | electrical_engineering              | 0.275862    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | elementary_mathematics              | 0.251323    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | formal_logic                        | 0.238095    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | global_facts                        | 0.31        |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_biology                 | 0.283871    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_chemistry               | 0.270936    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | human_aging                         | 0.394619    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_european_history        | 0.260606    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_geography               | 0.277778    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_government_and_politics | 0.248705    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_mathematics             | 0.248148    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | human_sexuality                     | 0.274809    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | marketing                           | 0.307692    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | jurisprudence                       | 0.287037    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | virology                            | 0.379518    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | world_religions                     | 0.28655     |                10 | tiiuae/falcon-7b                              |
| world_knowledge          | bigbench_misconceptions          |                                     | 0.52968     |                10 | tiiuae/falcon-7b                              |
| world_knowledge          | bigbench_movie_recommendation    |                                     | 0.256       |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | abstract_algebra                    | 0.34        |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          | mmlu                             | Average                             | 0.264146    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          | arc_challenge                    |                                     | 0.421502    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          | arc_easy                         |                                     | 0.675926    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          | bigbench_qa_wikidata             |                                     | 0.390335    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          | triviaqa                         |                                     | 0.00106073  |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | world_history                       | 0.367292    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | word_origins                        | 0.0821918   |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | science                             | 0.113445    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | literature                          | 0.27551     |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | american_history                    | 0.309927    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | us_foreign_policy                   | 0.38        |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | international_law                   | 0.181818    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | sociology                           | 0.318408    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | public_relations                    | 0.281818    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | logical_fallacies                   | 0.276074    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | machine_learning                    | 0.375       |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | management                          | 0.281553    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | college_mathematics                 | 0.26        |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | medical_genetics                    | 0.33        |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | miscellaneous                       | 0.315453    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | moral_disputes                      | 0.309249    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | moral_scenarios                     | 0.251397    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | nutrition                           | 0.29085     |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | philosophy                          | 0.247588    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | prehistory                          | 0.320988    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | professional_accounting             | 0.29078     |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | professional_law                    | 0.243807    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | professional_medicine               | 0.169118    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | professional_psychology             | 0.267974    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | security_studies                    | 0.355102    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | college_computer_science            | 0.27        |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | astronomy                           | 0.236842    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | college_biology                     | 0.243056    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | medical_genetics                    | 0.23        |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | miscellaneous                       | 0.300128    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | moral_disputes                      | 0.277457    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | moral_scenarios                     | 0.236872    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | nutrition                           | 0.27451     |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | philosophy                          | 0.29582     |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | marketing                           | 0.264957    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | prehistory                          | 0.299383    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | professional_law                    | 0.259452    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | professional_medicine               | 0.161765    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | professional_psychology             | 0.256536    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | public_relations                    | 0.309091    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | security_studies                    | 0.289796    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | sociology                           | 0.253731    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | professional_accounting             | 0.27305     |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | management                          | 0.23301     |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | machine_learning                    | 0.339286    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | logical_fallacies                   | 0.245399    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_european_history        | 0.236364    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_geography               | 0.267677    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_government_and_politics | 0.217617    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_macroeconomics          | 0.230769    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_mathematics             | 0.244444    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_microeconomics          | 0.281513    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_physics                 | 0.238411    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_psychology              | 0.218349    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_statistics              | 0.208333    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_us_history              | 0.27451     |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_world_history           | 0.324895    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | human_aging                         | 0.345291    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | human_sexuality                     | 0.282443    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | international_law                   | 0.247934    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | jurisprudence                       | 0.342593    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | us_foreign_policy                   | 0.31        |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | virology                            | 0.259036    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | world_religions                     | 0.298246    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          | bigbench_misconceptions          |                                     | 0.525114    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          | jeopardy                         | Average                             | 0.455781    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | american_history                    | 0.498789    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | literature                          | 0.589796    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | science                             | 0.35084     |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | word_origins                        | 0.265753    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | world_history                       | 0.573727    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          | bigbench_qa_wikidata             |                                     | 0.700507    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          | arc_easy                         |                                     | 0.757576    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          | arc_challenge                    |                                     | 0.469283    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          | mmlu                             | Average                             | 0.277556    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | abstract_algebra                    | 0.29        |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | anatomy                             | 0.288889    |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_chemistry               | 0.285714    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | business_ethics                     | 0.27        |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | clinical_knowledge                  | 0.30566     |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | anatomy                             | 0.222222    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | college_chemistry                   | 0.2         |                10 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | astronomy                           | 0.282895    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | clinical_knowledge                  | 0.283019    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          | bigbench_movie_recommendation    |                                     | 0.25        |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | high_school_biology                 | 0.222581    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | global_facts                        | 0.32        |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | formal_logic                        | 0.190476    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | elementary_mathematics              | 0.227513    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | electrical_engineering              | 0.255172    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | econometrics                        | 0.280702    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | conceptual_physics                  | 0.310638    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | computer_security                   | 0.33        |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | college_physics                     | 0.186275    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | college_medicine                    | 0.312139    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | college_mathematics                 | 0.2         |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | college_computer_science            | 0.24        |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | college_chemistry                   | 0.24        |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | college_biology                     | 0.208333    |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          |                                  | business_ethics                     | 0.22        |                 0 | tiiuae/falcon-7b                              |
| world_knowledge          | jeopardy                         | Average                             | 0.229673    |                 0 | tiiuae/falcon-7b                              |
| commonsense_reasoning    | copa                             |                                     | 0.8         |                 0 | mosaicml/mpt-7b                               |
| commonsense_reasoning    | piqa                             |                                     | 0.799238    |                 0 | mosaicml/mpt-7b                               |
| commonsense_reasoning    | bigbench_strategy_qa             |                                     | 0.559196    |                 0 | mosaicml/mpt-7b                               |
| commonsense_reasoning    | piqa                             |                                     | 0.804679    |                10 | mosaicml/mpt-7b                               |
| commonsense_reasoning    | bigbench_strange_stories         |                                     | 0.609195    |                10 | mosaicml/mpt-7b                               |
| commonsense_reasoning    | bigbench_strategy_qa             |                                     | 0.564875    |                10 | mosaicml/mpt-7b                               |
| commonsense_reasoning    | bigbench_novel_concepts          |                                     | 0.5625      |                10 | mosaicml/mpt-7b                               |
| commonsense_reasoning    | bigbench_strange_stories         |                                     | 0.614943    |                 0 | mosaicml/mpt-7b                               |
| commonsense_reasoning    | bigbench_novel_concepts          |                                     | 0.4375      |                 0 | mosaicml/mpt-7b                               |
| commonsense_reasoning    | openbook_qa                      |                                     | 0.418       |                 0 | mosaicml/mpt-7b                               |
| language_understanding   | hellaswag                        |                                     | 0.765485    |                10 | mosaicml/mpt-7b                               |
| language_understanding   | bigbench_language_identification |                                     | 0.2498      |                10 | mosaicml/mpt-7b                               |
| language_understanding   | bigbench_conceptual_combinations |                                     | 0.320388    |                10 | mosaicml/mpt-7b                               |
| language_understanding   | bigbench_conlang_translation     |                                     | 0.0670732   |                 0 | mosaicml/mpt-7b                               |
| language_understanding   | lambada_openai                   |                                     | 0.70328     |                 0 | mosaicml/mpt-7b                               |
| language_understanding   | hellaswag                        |                                     | 0.761701    |                 0 | mosaicml/mpt-7b                               |
| language_understanding   | winograd                         |                                     | 0.868132    |                 0 | mosaicml/mpt-7b                               |
| language_understanding   | bigbench_conceptual_combinations |                                     | 0.339806    |                 0 | mosaicml/mpt-7b                               |
| language_understanding   | bigbench_language_identification |                                     | 0.2526      |                 0 | mosaicml/mpt-7b                               |
| language_understanding   | bigbench_conlang_translation     |                                     | 0.0609756   |                10 | mosaicml/mpt-7b                               |
| language_understanding   | winogrande                       |                                     | 0.685083    |                 0 | mosaicml/mpt-7b                               |
| reading_comprehension    | squad                            |                                     | 0           |                 0 | mosaicml/mpt-7b                               |
| reading_comprehension    | bigbench_understanding_fables    |                                     | 0.259259    |                10 | mosaicml/mpt-7b                               |
| reading_comprehension    | bigbench_understanding_fables    |                                     | 0.259259    |                 0 | mosaicml/mpt-7b                               |
| reading_comprehension    | boolq                            |                                     | 0.748012    |                 0 | mosaicml/mpt-7b                               |
| reading_comprehension    | pubmed_qa_labeled                |                                     | 0           |                10 | mosaicml/mpt-7b                               |
| reading_comprehension    | squad                            |                                     | 0           |                10 | mosaicml/mpt-7b                               |
| reading_comprehension    | coqa                             |                                     | 0           |                10 | mosaicml/mpt-7b                               |
| reading_comprehension    | pubmed_qa_labeled                |                                     | 0           |                 0 | mosaicml/mpt-7b                               |
| reading_comprehension    | coqa                             |                                     | 0           |                 0 | mosaicml/mpt-7b                               |
| reading_comprehension    | boolq                            |                                     | 0.747706    |                10 | mosaicml/mpt-7b                               |
| symbolic_problem_solving | bigbench_elementary_math_qa      |                                     | 0.228512    |                10 | mosaicml/mpt-7b                               |
| symbolic_problem_solving | bigbench_operators               |                                     | 0.2         |                 0 | mosaicml/mpt-7b                               |
| symbolic_problem_solving | bigbench_logical_deduction       |                                     | 0.282       |                 0 | mosaicml/mpt-7b                               |
| symbolic_problem_solving | bigbench_cs_algorithms           |                                     | 0.0325758   |                 0 | mosaicml/mpt-7b                               |
| symbolic_problem_solving | bigbench_dyck_languages          |                                     | 0.056       |                 0 | mosaicml/mpt-7b                               |
| symbolic_problem_solving | bigbench_elementary_math_qa      |                                     | 0.244471    |                 0 | mosaicml/mpt-7b                               |
| symbolic_problem_solving | simple_arithmetic_withspaces     |                                     | 0.008       |                 0 | mosaicml/mpt-7b                               |
| symbolic_problem_solving | bigbench_dyck_languages          |                                     | 0.318       |                10 | mosaicml/mpt-7b                               |
| symbolic_problem_solving | bigbench_cs_algorithms           |                                     | 0.478788    |                10 | mosaicml/mpt-7b                               |
| symbolic_problem_solving | bigbench_repeat_copy_logic       |                                     | 0           |                 0 | mosaicml/mpt-7b                               |
| symbolic_problem_solving | bigbench_logical_deduction       |                                     | 0.267333    |                10 | mosaicml/mpt-7b                               |
| symbolic_problem_solving | bigbench_repeat_copy_logic       |                                     | 0.25        |                10 | mosaicml/mpt-7b                               |
| symbolic_problem_solving | simple_arithmetic_nospaces       |                                     | 0.081       |                10 | mosaicml/mpt-7b                               |
| symbolic_problem_solving | simple_arithmetic_withspaces     |                                     | 0           |                10 | mosaicml/mpt-7b                               |
| symbolic_problem_solving | math_qa                          |                                     | 0.25176     |                10 | mosaicml/mpt-7b                               |
| symbolic_problem_solving | logi_qa                          |                                     | 0.261137    |                10 | mosaicml/mpt-7b                               |
| symbolic_problem_solving | math_qa                          |                                     | 0.248743    |                 0 | mosaicml/mpt-7b                               |
| symbolic_problem_solving | logi_qa                          |                                     | 0.22427     |                 0 | mosaicml/mpt-7b                               |
| symbolic_problem_solving | bigbench_operators               |                                     | 0.342857    |                10 | mosaicml/mpt-7b                               |
| symbolic_problem_solving | simple_arithmetic_nospaces       |                                     | 0           |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_psychology              | 0.249541    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_computer_science        | 0.33        |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_statistics              | 0.236111    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_us_history              | 0.264706    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_world_history           | 0.270042    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_physics                 | 0.304636    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_microeconomics          | 0.289916    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_computer_science        | 0.33        |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_macroeconomics          | 0.25641     |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | college_medicine                    | 0.225434    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | college_physics                     | 0.215686    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | computer_security                   | 0.29        |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | conceptual_physics                  | 0.293617    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | econometrics                        | 0.201754    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | electrical_engineering              | 0.241379    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | elementary_mathematics              | 0.277778    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | formal_logic                        | 0.246032    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | global_facts                        | 0.29        |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_biology                 | 0.280645    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_chemistry               | 0.231527    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | human_aging                         | 0.367713    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_european_history        | 0.290909    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_geography               | 0.308081    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_government_and_politics | 0.305699    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_mathematics             | 0.266667    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | human_sexuality                     | 0.267176    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | marketing                           | 0.264957    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | jurisprudence                       | 0.324074    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | virology                            | 0.379518    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | world_religions                     | 0.263158    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          | bigbench_misconceptions          |                                     | 0.520548    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          | bigbench_movie_recommendation    |                                     | 0.25        |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | abstract_algebra                    | 0.32        |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          | mmlu                             | Average                             | 0.293343    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          | arc_challenge                    |                                     | 0.396758    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          | arc_easy                         |                                     | 0.67298     |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          | bigbench_qa_wikidata             |                                     | 0.397077    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          | triviaqa                         |                                     | 0.343145    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | world_history                       | 0.461126    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | word_origins                        | 0.115068    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | science                             | 0.138655    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | literature                          | 0.318367    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | american_history                    | 0.365617    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | us_foreign_policy                   | 0.3         |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | international_law                   | 0.297521    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | sociology                           | 0.268657    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | public_relations                    | 0.327273    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | logical_fallacies                   | 0.220859    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | machine_learning                    | 0.294643    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | management                          | 0.291262    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | college_mathematics                 | 0.31        |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | medical_genetics                    | 0.32        |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | miscellaneous                       | 0.309068    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | moral_disputes                      | 0.291908    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | moral_scenarios                     | 0.251397    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | nutrition                           | 0.303922    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | philosophy                          | 0.337621    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | prehistory                          | 0.342593    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | professional_accounting             | 0.287234    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | professional_law                    | 0.280313    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | professional_medicine               | 0.213235    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | professional_psychology             | 0.272876    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | security_studies                    | 0.285714    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | college_computer_science            | 0.22        |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | astronomy                           | 0.309211    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | college_biology                     | 0.277778    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | medical_genetics                    | 0.26        |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | miscellaneous                       | 0.374202    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | moral_disputes                      | 0.315029    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | moral_scenarios                     | 0.248045    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | nutrition                           | 0.310458    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | philosophy                          | 0.33119     |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | marketing                           | 0.324786    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | prehistory                          | 0.345679    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | professional_law                    | 0.290091    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | professional_medicine               | 0.205882    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | professional_psychology             | 0.289216    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | public_relations                    | 0.272727    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | security_studies                    | 0.236735    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | sociology                           | 0.293532    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | professional_accounting             | 0.276596    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | management                          | 0.320388    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | machine_learning                    | 0.267857    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | logical_fallacies                   | 0.368098    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_european_history        | 0.254545    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_geography               | 0.333333    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_government_and_politics | 0.321244    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_macroeconomics          | 0.266667    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_mathematics             | 0.240741    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_microeconomics          | 0.268908    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_physics                 | 0.271523    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_psychology              | 0.286239    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_statistics              | 0.185185    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_us_history              | 0.308824    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_world_history           | 0.2827      |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | human_aging                         | 0.246637    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | human_sexuality                     | 0.274809    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | international_law                   | 0.413223    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | jurisprudence                       | 0.324074    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | us_foreign_policy                   | 0.35        |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | virology                            | 0.277108    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | world_religions                     | 0.397661    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          | bigbench_misconceptions          |                                     | 0.479452    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          | jeopardy                         | Average                             | 0.467253    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | american_history                    | 0.520581    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | literature                          | 0.571429    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | science                             | 0.369748    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | word_origins                        | 0.273973    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | world_history                       | 0.600536    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          | bigbench_qa_wikidata             |                                     | 0.711038    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          | arc_easy                         |                                     | 0.722643    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          | arc_challenge                    |                                     | 0.433447    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          | mmlu                             | Average                             | 0.279823    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | abstract_algebra                    | 0.28        |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | anatomy                             | 0.237037    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_chemistry               | 0.285714    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | business_ethics                     | 0.31        |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | clinical_knowledge                  | 0.256604    |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | anatomy                             | 0.355556    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | college_chemistry                   | 0.22        |                10 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | astronomy                           | 0.256579    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | clinical_knowledge                  | 0.30566     |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          | bigbench_movie_recommendation    |                                     | 0.244       |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | high_school_biology                 | 0.306452    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | global_facts                        | 0.34        |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | formal_logic                        | 0.277778    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | elementary_mathematics              | 0.304233    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | electrical_engineering              | 0.310345    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | econometrics                        | 0.263158    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | conceptual_physics                  | 0.251064    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | computer_security                   | 0.33        |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | college_physics                     | 0.22549     |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | college_medicine                    | 0.289017    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | college_mathematics                 | 0.27        |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | college_computer_science            | 0.27        |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | college_chemistry                   | 0.21        |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | college_biology                     | 0.305556    |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          |                                  | business_ethics                     | 0.28        |                 0 | mosaicml/mpt-7b                               |
| world_knowledge          | jeopardy                         | Average                             | 0.279767    |                 0 | mosaicml/mpt-7b                               |
| commonsense_reasoning    | copa                             |                                     | 0.83        |                 0 | mosaicml/mpt-7b-instruct                      |
| commonsense_reasoning    | piqa                             |                                     | 0.803591    |                 0 | mosaicml/mpt-7b-instruct                      |
| commonsense_reasoning    | bigbench_strategy_qa             |                                     | 0.587593    |                 0 | mosaicml/mpt-7b-instruct                      |
| commonsense_reasoning    | piqa                             |                                     | 0.806311    |                10 | mosaicml/mpt-7b-instruct                      |
| commonsense_reasoning    | bigbench_strange_stories         |                                     | 0.609195    |                10 | mosaicml/mpt-7b-instruct                      |
| commonsense_reasoning    | bigbench_strategy_qa             |                                     | 0.59633     |                10 | mosaicml/mpt-7b-instruct                      |
| commonsense_reasoning    | bigbench_novel_concepts          |                                     | 0.53125     |                10 | mosaicml/mpt-7b-instruct                      |
| commonsense_reasoning    | bigbench_strange_stories         |                                     | 0.643678    |                 0 | mosaicml/mpt-7b-instruct                      |
| commonsense_reasoning    | bigbench_novel_concepts          |                                     | 0.53125     |                 0 | mosaicml/mpt-7b-instruct                      |
| commonsense_reasoning    | openbook_qa                      |                                     | 0.436       |                 0 | mosaicml/mpt-7b-instruct                      |
| language_understanding   | hellaswag                        |                                     | 0.769767    |                10 | mosaicml/mpt-7b-instruct                      |
| language_understanding   | bigbench_language_identification |                                     | 0.2497      |                10 | mosaicml/mpt-7b-instruct                      |
| language_understanding   | bigbench_conceptual_combinations |                                     | 0.320388    |                10 | mosaicml/mpt-7b-instruct                      |
| language_understanding   | bigbench_conlang_translation     |                                     | 0.0670732   |                 0 | mosaicml/mpt-7b-instruct                      |
| language_understanding   | lambada_openai                   |                                     | 0.69086     |                 0 | mosaicml/mpt-7b-instruct                      |
| language_understanding   | hellaswag                        |                                     | 0.769966    |                 0 | mosaicml/mpt-7b-instruct                      |
| language_understanding   | winograd                         |                                     | 0.846154    |                 0 | mosaicml/mpt-7b-instruct                      |
| language_understanding   | bigbench_conceptual_combinations |                                     | 0.378641    |                 0 | mosaicml/mpt-7b-instruct                      |
| language_understanding   | bigbench_language_identification |                                     | 0.2609      |                 0 | mosaicml/mpt-7b-instruct                      |
| language_understanding   | bigbench_conlang_translation     |                                     | 0.0426829   |                10 | mosaicml/mpt-7b-instruct                      |
| language_understanding   | winogrande                       |                                     | 0.67719     |                 0 | mosaicml/mpt-7b-instruct                      |
| reading_comprehension    | squad                            |                                     | 0.000283822 |                 0 | mosaicml/mpt-7b-instruct                      |
| reading_comprehension    | bigbench_understanding_fables    |                                     | 0.26455     |                10 | mosaicml/mpt-7b-instruct                      |
| reading_comprehension    | bigbench_understanding_fables    |                                     | 0.259259    |                 0 | mosaicml/mpt-7b-instruct                      |
| reading_comprehension    | boolq                            |                                     | 0.751988    |                 0 | mosaicml/mpt-7b-instruct                      |
| reading_comprehension    | pubmed_qa_labeled                |                                     | 0           |                10 | mosaicml/mpt-7b-instruct                      |
| reading_comprehension    | squad                            |                                     | 9.46074e-05 |                10 | mosaicml/mpt-7b-instruct                      |
| reading_comprehension    | coqa                             |                                     | 0           |                10 | mosaicml/mpt-7b-instruct                      |
| reading_comprehension    | pubmed_qa_labeled                |                                     | 0           |                 0 | mosaicml/mpt-7b-instruct                      |
| reading_comprehension    | coqa                             |                                     | 0           |                 0 | mosaicml/mpt-7b-instruct                      |
| reading_comprehension    | boolq                            |                                     | 0.777064    |                10 | mosaicml/mpt-7b-instruct                      |
| symbolic_problem_solving | bigbench_elementary_math_qa      |                                     | 0.227437    |                10 | mosaicml/mpt-7b-instruct                      |
| symbolic_problem_solving | bigbench_operators               |                                     | 0.309524    |                 0 | mosaicml/mpt-7b-instruct                      |
| symbolic_problem_solving | bigbench_logical_deduction       |                                     | 0.302       |                 0 | mosaicml/mpt-7b-instruct                      |
| symbolic_problem_solving | bigbench_cs_algorithms           |                                     | 0.0598485   |                 0 | mosaicml/mpt-7b-instruct                      |
| symbolic_problem_solving | bigbench_dyck_languages          |                                     | 0.067       |                 0 | mosaicml/mpt-7b-instruct                      |
| symbolic_problem_solving | bigbench_elementary_math_qa      |                                     | 0.246908    |                 0 | mosaicml/mpt-7b-instruct                      |
| symbolic_problem_solving | simple_arithmetic_withspaces     |                                     | 0.021       |                 0 | mosaicml/mpt-7b-instruct                      |
| symbolic_problem_solving | bigbench_dyck_languages          |                                     | 0.314       |                10 | mosaicml/mpt-7b-instruct                      |
| symbolic_problem_solving | bigbench_cs_algorithms           |                                     | 0.496212    |                10 | mosaicml/mpt-7b-instruct                      |
| symbolic_problem_solving | bigbench_repeat_copy_logic       |                                     | 0.03125     |                 0 | mosaicml/mpt-7b-instruct                      |
| symbolic_problem_solving | bigbench_logical_deduction       |                                     | 0.268667    |                10 | mosaicml/mpt-7b-instruct                      |
| symbolic_problem_solving | bigbench_repeat_copy_logic       |                                     | 0.3125      |                10 | mosaicml/mpt-7b-instruct                      |
| symbolic_problem_solving | simple_arithmetic_nospaces       |                                     | 0.078       |                10 | mosaicml/mpt-7b-instruct                      |
| symbolic_problem_solving | simple_arithmetic_withspaces     |                                     | 0           |                10 | mosaicml/mpt-7b-instruct                      |
| symbolic_problem_solving | math_qa                          |                                     | 0.248072    |                10 | mosaicml/mpt-7b-instruct                      |
| symbolic_problem_solving | logi_qa                          |                                     | 0.264209    |                10 | mosaicml/mpt-7b-instruct                      |
| symbolic_problem_solving | math_qa                          |                                     | 0.247402    |                 0 | mosaicml/mpt-7b-instruct                      |
| symbolic_problem_solving | logi_qa                          |                                     | 0.247312    |                 0 | mosaicml/mpt-7b-instruct                      |
| symbolic_problem_solving | bigbench_operators               |                                     | 0.352381    |                10 | mosaicml/mpt-7b-instruct                      |
| symbolic_problem_solving | simple_arithmetic_nospaces       |                                     | 0           |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_psychology              | 0.308257    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_computer_science        | 0.41        |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_statistics              | 0.388889    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_us_history              | 0.27451     |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_world_history           | 0.261603    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_physics                 | 0.311258    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_microeconomics          | 0.331933    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_computer_science        | 0.29        |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_macroeconomics          | 0.323077    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | college_medicine                    | 0.271676    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | college_physics                     | 0.264706    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | computer_security                   | 0.37        |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | conceptual_physics                  | 0.33617     |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | econometrics                        | 0.192982    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | electrical_engineering              | 0.324138    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | elementary_mathematics              | 0.267196    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | formal_logic                        | 0.301587    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | global_facts                        | 0.35        |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_biology                 | 0.33871     |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_chemistry               | 0.270936    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | human_aging                         | 0.372197    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_european_history        | 0.30303     |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_geography               | 0.388889    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_government_and_politics | 0.362694    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_mathematics             | 0.288889    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | human_sexuality                     | 0.374046    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | marketing                           | 0.320513    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | jurisprudence                       | 0.342593    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | virology                            | 0.385542    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | world_religions                     | 0.263158    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          | bigbench_misconceptions          |                                     | 0.598173    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          | bigbench_movie_recommendation    |                                     | 0.246       |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | abstract_algebra                    | 0.29        |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          | mmlu                             | Average                             | 0.342622    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          | arc_challenge                    |                                     | 0.430034    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          | arc_easy                         |                                     | 0.683502    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          | bigbench_qa_wikidata             |                                     | 0.38128     |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          | triviaqa                         |                                     | 0.330593    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | world_history                       | 0.453083    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | word_origins                        | 0.136986    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | science                             | 0.168067    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | literature                          | 0.391837    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | american_history                    | 0.353511    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | us_foreign_policy                   | 0.37        |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | international_law                   | 0.31405     |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | sociology                           | 0.308458    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | public_relations                    | 0.418182    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | logical_fallacies                   | 0.226994    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | machine_learning                    | 0.241071    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | management                          | 0.339806    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | college_mathematics                 | 0.29        |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | medical_genetics                    | 0.34        |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | miscellaneous                       | 0.386973    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | moral_disputes                      | 0.323699    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | moral_scenarios                     | 0.251397    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | nutrition                           | 0.366013    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | philosophy                          | 0.37299     |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | prehistory                          | 0.33642     |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | professional_accounting             | 0.27305     |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | professional_law                    | 0.273794    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | professional_medicine               | 0.220588    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | professional_psychology             | 0.287582    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | security_studies                    | 0.334694    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | college_computer_science            | 0.29        |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | astronomy                           | 0.315789    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | college_biology                     | 0.256944    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | medical_genetics                    | 0.3         |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | miscellaneous                       | 0.445722    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | moral_disputes                      | 0.309249    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | moral_scenarios                     | 0.241341    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | nutrition                           | 0.362745    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | philosophy                          | 0.350482    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | marketing                           | 0.418803    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | prehistory                          | 0.401235    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | professional_law                    | 0.300522    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | professional_medicine               | 0.316176    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | professional_psychology             | 0.297386    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | public_relations                    | 0.336364    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | security_studies                    | 0.355102    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | sociology                           | 0.378109    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | professional_accounting             | 0.280142    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | management                          | 0.407767    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | machine_learning                    | 0.330357    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | logical_fallacies                   | 0.288344    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_european_history        | 0.266667    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_geography               | 0.459596    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_government_and_politics | 0.450777    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_macroeconomics          | 0.328205    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_mathematics             | 0.259259    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_microeconomics          | 0.352941    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_physics                 | 0.298013    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_psychology              | 0.377982    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_statistics              | 0.324074    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_us_history              | 0.313726    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_world_history           | 0.303797    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | human_aging                         | 0.295964    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | human_sexuality                     | 0.335878    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | international_law                   | 0.438017    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | jurisprudence                       | 0.37037     |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | us_foreign_policy                   | 0.48        |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | virology                            | 0.433735    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | world_religions                     | 0.397661    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          | bigbench_misconceptions          |                                     | 0.584475    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          | jeopardy                         | Average                             | 0.456659    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | american_history                    | 0.510896    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | literature                          | 0.540816    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | science                             | 0.34874     |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | word_origins                        | 0.287671    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | world_history                       | 0.595174    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          | bigbench_qa_wikidata             |                                     | 0.694503    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          | arc_easy                         |                                     | 0.748737    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          | arc_challenge                    |                                     | 0.47099     |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          | mmlu                             | Average                             | 0.313084    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | abstract_algebra                    | 0.31        |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | anatomy                             | 0.311111    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_chemistry               | 0.275862    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | business_ethics                     | 0.26        |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | clinical_knowledge                  | 0.316981    |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | anatomy                             | 0.414815    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | college_chemistry                   | 0.33        |                10 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | astronomy                           | 0.25        |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | clinical_knowledge                  | 0.354717    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          | bigbench_movie_recommendation    |                                     | 0.244       |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | high_school_biology                 | 0.377419    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | global_facts                        | 0.34        |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | formal_logic                        | 0.277778    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | elementary_mathematics              | 0.296296    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | electrical_engineering              | 0.413793    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | econometrics                        | 0.263158    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | conceptual_physics                  | 0.306383    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | computer_security                   | 0.41        |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | college_physics                     | 0.27451     |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | college_medicine                    | 0.317919    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | college_mathematics                 | 0.33        |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | college_computer_science            | 0.3         |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | college_chemistry                   | 0.32        |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | college_biology                     | 0.340278    |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          |                                  | business_ethics                     | 0.36        |                 0 | mosaicml/mpt-7b-instruct                      |
| world_knowledge          | jeopardy                         | Average                             | 0.300697    |                 0 | mosaicml/mpt-7b-instruct                      |
| commonsense_reasoning    | copa                             |                                     | 0.81        |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| commonsense_reasoning    | piqa                             |                                     | 0.765506    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| commonsense_reasoning    | bigbench_strategy_qa             |                                     | 0.559196    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| commonsense_reasoning    | piqa                             |                                     | 0.782372    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| commonsense_reasoning    | bigbench_strange_stories         |                                     | 0.591954    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| commonsense_reasoning    | bigbench_strategy_qa             |                                     | 0.562691    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| commonsense_reasoning    | bigbench_novel_concepts          |                                     | 0.5625      |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| commonsense_reasoning    | bigbench_strange_stories         |                                     | 0.58046     |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| commonsense_reasoning    | bigbench_novel_concepts          |                                     | 0.34375     |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| commonsense_reasoning    | openbook_qa                      |                                     | 0.408       |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| language_understanding   | hellaswag                        |                                     | 0.710317    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| language_understanding   | bigbench_language_identification |                                     | 0.2689      |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| language_understanding   | bigbench_conceptual_combinations |                                     | 0.359223    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| language_understanding   | bigbench_conlang_translation     |                                     | 0.0426829   |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| language_understanding   | lambada_openai                   |                                     | 0.689113    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| language_understanding   | hellaswag                        |                                     | 0.703346    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| language_understanding   | winograd                         |                                     | 0.820513    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| language_understanding   | bigbench_conceptual_combinations |                                     | 0.330097    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| language_understanding   | bigbench_language_identification |                                     | 0.2678      |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| language_understanding   | bigbench_conlang_translation     |                                     | 0.0365854   |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| language_understanding   | winogrande                       |                                     | 0.656669    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| reading_comprehension    | squad                            |                                     | 0           |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| reading_comprehension    | bigbench_understanding_fables    |                                     | 0.306878    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| reading_comprehension    | bigbench_understanding_fables    |                                     | 0.280423    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| reading_comprehension    | boolq                            |                                     | 0.65841     |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| reading_comprehension    | pubmed_qa_labeled                |                                     | 0           |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| reading_comprehension    | squad                            |                                     | 0           |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| reading_comprehension    | coqa                             |                                     | 0           |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| reading_comprehension    | pubmed_qa_labeled                |                                     | 0           |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| reading_comprehension    | coqa                             |                                     | 0           |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| reading_comprehension    | boolq                            |                                     | 0.720489    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| symbolic_problem_solving | bigbench_elementary_math_qa      |                                     | 0.246541    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| symbolic_problem_solving | bigbench_operators               |                                     | 0.147619    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| symbolic_problem_solving | bigbench_logical_deduction       |                                     | 0.258667    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| symbolic_problem_solving | bigbench_cs_algorithms           |                                     | 0.025       |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| symbolic_problem_solving | bigbench_dyck_languages          |                                     | 0           |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| symbolic_problem_solving | bigbench_elementary_math_qa      |                                     | 0.248559    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| symbolic_problem_solving | simple_arithmetic_withspaces     |                                     | 0.002       |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| symbolic_problem_solving | bigbench_dyck_languages          |                                     | 0.205       |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| symbolic_problem_solving | bigbench_cs_algorithms           |                                     | 0.487121    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| symbolic_problem_solving | bigbench_repeat_copy_logic       |                                     | 0.125       |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| symbolic_problem_solving | bigbench_logical_deduction       |                                     | 0.262667    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| symbolic_problem_solving | bigbench_repeat_copy_logic       |                                     | 0.90625     |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| symbolic_problem_solving | simple_arithmetic_nospaces       |                                     | 0.044       |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| symbolic_problem_solving | simple_arithmetic_withspaces     |                                     | 0           |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| symbolic_problem_solving | math_qa                          |                                     | 0.248072    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| symbolic_problem_solving | logi_qa                          |                                     | 0.313364    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| symbolic_problem_solving | math_qa                          |                                     | 0.251425    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| symbolic_problem_solving | logi_qa                          |                                     | 0.276498    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| symbolic_problem_solving | bigbench_operators               |                                     | 0.304762    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| symbolic_problem_solving | simple_arithmetic_nospaces       |                                     | 0           |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_psychology              | 0.480734    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_computer_science        | 0.27        |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_statistics              | 0.222222    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_us_history              | 0.426471    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_world_history           | 0.472574    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_physics                 | 0.258278    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_microeconomics          | 0.357143    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_computer_science        | 0.34        |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_macroeconomics          | 0.369231    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | college_medicine                    | 0.364162    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | college_physics                     | 0.294118    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | computer_security                   | 0.55        |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | conceptual_physics                  | 0.306383    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | econometrics                        | 0.210526    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | electrical_engineering              | 0.275862    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | elementary_mathematics              | 0.291005    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | formal_logic                        | 0.277778    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | global_facts                        | 0.35        |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_biology                 | 0.432258    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_chemistry               | 0.315271    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | human_aging                         | 0.488789    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_european_history        | 0.448485    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_geography               | 0.439394    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_government_and_politics | 0.507772    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_mathematics             | 0.262963    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | human_sexuality                     | 0.389313    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | marketing                           | 0.525641    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | jurisprudence                       | 0.435185    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | virology                            | 0.319277    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | world_religions                     | 0.520468    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          | bigbench_misconceptions          |                                     | 0.538813    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          | bigbench_movie_recommendation    |                                     | 0.244       |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | abstract_algebra                    | 0.29        |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          | mmlu                             | Average                             | 0.323266    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          | arc_challenge                    |                                     | 0.41041     |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          | arc_easy                         |                                     | 0.683502    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          | bigbench_qa_wikidata             |                                     | 0.431327    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          | triviaqa                         |                                     | 0.233095    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | world_history                       | 0.184987    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | word_origins                        | 0.0246575   |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | science                             | 0.0693277   |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | literature                          | 0.044898    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | american_history                    | 0.0992736   |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | us_foreign_policy                   | 0.5         |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | international_law                   | 0.512397    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | sociology                           | 0.412935    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | public_relations                    | 0.472727    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | logical_fallacies                   | 0.429448    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | machine_learning                    | 0.267857    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | management                          | 0.436893    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | college_mathematics                 | 0.32        |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | medical_genetics                    | 0.42        |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | miscellaneous                       | 0.521073    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | moral_disputes                      | 0.410405    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | moral_scenarios                     | 0.248045    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | nutrition                           | 0.372549    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | philosophy                          | 0.398714    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | prehistory                          | 0.441358    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | professional_accounting             | 0.315603    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | professional_law                    | 0.326597    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | professional_medicine               | 0.257353    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | professional_psychology             | 0.366013    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | security_studies                    | 0.24898     |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | college_computer_science            | 0.35        |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | astronomy                           | 0.388158    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | college_biology                     | 0.375       |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | medical_genetics                    | 0.38        |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | miscellaneous                       | 0.476373    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | moral_disputes                      | 0.32948     |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | moral_scenarios                     | 0.232402    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | nutrition                           | 0.339869    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | philosophy                          | 0.33119     |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | marketing                           | 0.418803    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | prehistory                          | 0.348765    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | professional_law                    | 0.308996    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | professional_medicine               | 0.264706    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | professional_psychology             | 0.272876    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | public_relations                    | 0.390909    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | security_studies                    | 0.285714    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | sociology                           | 0.323383    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | professional_accounting             | 0.258865    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | management                          | 0.31068     |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | machine_learning                    | 0.267857    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | logical_fallacies                   | 0.398773    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_european_history        | 0.290909    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_geography               | 0.40404     |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_government_and_politics | 0.419689    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_macroeconomics          | 0.307692    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_mathematics             | 0.240741    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_microeconomics          | 0.323529    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_physics                 | 0.251656    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_psychology              | 0.407339    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_statistics              | 0.240741    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_us_history              | 0.328431    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_world_history           | 0.333333    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | human_aging                         | 0.304933    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | human_sexuality                     | 0.267176    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | international_law                   | 0.380165    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | jurisprudence                       | 0.305556    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | us_foreign_policy                   | 0.44        |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | virology                            | 0.295181    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | world_religions                     | 0.450292    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          | bigbench_misconceptions          |                                     | 0.520548    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          | jeopardy                         | Average                             | 0.448388    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | american_history                    | 0.513317    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | literature                          | 0.569388    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | science                             | 0.336134    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | word_origins                        | 0.252055    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | world_history                       | 0.571046    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          | bigbench_qa_wikidata             |                                     | 0.733133    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          | arc_easy                         |                                     | 0.715488    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          | arc_challenge                    |                                     | 0.425768    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          | mmlu                             | Average                             | 0.377841    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | abstract_algebra                    | 0.31        |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | anatomy                             | 0.422222    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_chemistry               | 0.280788    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | business_ethics                     | 0.35        |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | clinical_knowledge                  | 0.411321    |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | anatomy                             | 0.333333    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | college_chemistry                   | 0.32        |                10 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | astronomy                           | 0.361842    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | clinical_knowledge                  | 0.411321    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          | bigbench_movie_recommendation    |                                     | 0.29        |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | high_school_biology                 | 0.332258    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | global_facts                        | 0.29        |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | formal_logic                        | 0.269841    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | elementary_mathematics              | 0.293651    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | electrical_engineering              | 0.331034    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | econometrics                        | 0.175439    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | conceptual_physics                  | 0.314894    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | computer_security                   | 0.4         |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | college_physics                     | 0.215686    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | college_medicine                    | 0.32948     |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | college_mathematics                 | 0.31        |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | college_computer_science            | 0.33        |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | college_chemistry                   | 0.32        |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | college_biology                     | 0.305556    |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          |                                  | business_ethics                     | 0.33        |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| world_knowledge          | jeopardy                         | Average                             | 0.0846287   |                 0 | togethercomputer/RedPajama-INCITE-7B-Instruct |
| commonsense_reasoning    | copa                             |                                     | 0.81        |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| commonsense_reasoning    | piqa                             |                                     | 0.777476    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| commonsense_reasoning    | bigbench_strategy_qa             |                                     | 0.543906    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| commonsense_reasoning    | piqa                             |                                     | 0.780196    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| commonsense_reasoning    | bigbench_strange_stories         |                                     | 0.591954    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| commonsense_reasoning    | bigbench_strategy_qa             |                                     | 0.532984    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| commonsense_reasoning    | bigbench_novel_concepts          |                                     | 0.53125     |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| commonsense_reasoning    | bigbench_strange_stories         |                                     | 0.568965    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| commonsense_reasoning    | bigbench_novel_concepts          |                                     | 0.375       |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| commonsense_reasoning    | openbook_qa                      |                                     | 0.416       |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| language_understanding   | hellaswag                        |                                     | 0.718084    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| language_understanding   | bigbench_language_identification |                                     | 0.2538      |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| language_understanding   | bigbench_conceptual_combinations |                                     | 0.368932    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| language_understanding   | bigbench_conlang_translation     |                                     | 0.0609756   |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| language_understanding   | lambada_openai                   |                                     | 0.713565    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| language_understanding   | hellaswag                        |                                     | 0.704641    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| language_understanding   | winograd                         |                                     | 0.864469    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| language_understanding   | bigbench_conceptual_combinations |                                     | 0.281553    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| language_understanding   | bigbench_language_identification |                                     | 0.2554      |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| language_understanding   | bigbench_conlang_translation     |                                     | 0.0487805   |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| language_understanding   | winogrande                       |                                     | 0.64483     |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| reading_comprehension    | squad                            |                                     | 9.46074e-05 |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| reading_comprehension    | bigbench_understanding_fables    |                                     | 0.243386    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| reading_comprehension    | bigbench_understanding_fables    |                                     | 0.195767    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| reading_comprehension    | boolq                            |                                     | 0.700306    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| reading_comprehension    | pubmed_qa_labeled                |                                     | 0           |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| reading_comprehension    | squad                            |                                     | 9.46074e-05 |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| reading_comprehension    | coqa                             |                                     | 0           |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| reading_comprehension    | pubmed_qa_labeled                |                                     | 0           |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| reading_comprehension    | coqa                             |                                     | 0           |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| reading_comprehension    | boolq                            |                                     | 0.620183    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| symbolic_problem_solving | bigbench_elementary_math_qa      |                                     | 0.2337      |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| symbolic_problem_solving | bigbench_operators               |                                     | 0.109524    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| symbolic_problem_solving | bigbench_logical_deduction       |                                     | 0.264       |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| symbolic_problem_solving | bigbench_cs_algorithms           |                                     | 0.0265152   |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| symbolic_problem_solving | bigbench_dyck_languages          |                                     | 0           |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| symbolic_problem_solving | bigbench_elementary_math_qa      |                                     | 0.238784    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| symbolic_problem_solving | simple_arithmetic_withspaces     |                                     | 0.006       |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| symbolic_problem_solving | bigbench_dyck_languages          |                                     | 0.326       |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| symbolic_problem_solving | bigbench_cs_algorithms           |                                     | 0.469697    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| symbolic_problem_solving | bigbench_repeat_copy_logic       |                                     | 0           |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| symbolic_problem_solving | bigbench_logical_deduction       |                                     | 0.25        |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| symbolic_problem_solving | bigbench_repeat_copy_logic       |                                     | 0.09375     |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| symbolic_problem_solving | simple_arithmetic_nospaces       |                                     | 0.042       |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| symbolic_problem_solving | simple_arithmetic_withspaces     |                                     | 0           |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| symbolic_problem_solving | math_qa                          |                                     | 0.241368    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| symbolic_problem_solving | logi_qa                          |                                     | 0.250384    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| symbolic_problem_solving | math_qa                          |                                     | 0.263493    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| symbolic_problem_solving | logi_qa                          |                                     | 0.25192     |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| symbolic_problem_solving | bigbench_operators               |                                     | 0.27619     |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| symbolic_problem_solving | simple_arithmetic_nospaces       |                                     | 0           |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_psychology              | 0.269725    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_computer_science        | 0.32        |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_statistics              | 0.208333    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_us_history              | 0.22549     |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_world_history           | 0.236287    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_physics                 | 0.304636    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_microeconomics          | 0.243697    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_computer_science        | 0.28        |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_macroeconomics          | 0.225641    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | college_medicine                    | 0.283237    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | college_physics                     | 0.254902    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | computer_security                   | 0.24        |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | conceptual_physics                  | 0.212766    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | econometrics                        | 0.254386    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | electrical_engineering              | 0.206897    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | elementary_mathematics              | 0.222222    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | formal_logic                        | 0.222222    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | global_facts                        | 0.22        |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_biology                 | 0.258065    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_chemistry               | 0.256158    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | human_aging                         | 0.197309    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_european_history        | 0.309091    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_geography               | 0.247475    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_government_and_politics | 0.227979    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_mathematics             | 0.285185    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | human_sexuality                     | 0.206107    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | marketing                           | 0.269231    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | jurisprudence                       | 0.222222    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | virology                            | 0.277108    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | world_religions                     | 0.245614    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          | bigbench_misconceptions          |                                     | 0.497717    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          | bigbench_movie_recommendation    |                                     | 0.23        |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | abstract_algebra                    | 0.35        |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          | mmlu                             | Average                             | 0.250095    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          | arc_challenge                    |                                     | 0.385666    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          | arc_easy                         |                                     | 0.651094    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          | bigbench_qa_wikidata             |                                     | 0.396044    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          | triviaqa                         |                                     | 0.412357    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | world_history                       | 0.466488    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | word_origins                        | 0.0465753   |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | science                             | 0.151261    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | literature                          | 0.34898     |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | american_history                    | 0.404358    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | us_foreign_policy                   | 0.26        |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | international_law                   | 0.31405     |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | sociology                           | 0.243781    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | public_relations                    | 0.209091    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | logical_fallacies                   | 0.251534    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | machine_learning                    | 0.232143    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | management                          | 0.23301     |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | college_mathematics                 | 0.35        |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | medical_genetics                    | 0.27        |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | miscellaneous                       | 0.246488    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | moral_disputes                      | 0.242775    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | moral_scenarios                     | 0.255866    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | nutrition                           | 0.287582    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | philosophy                          | 0.26045     |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | prehistory                          | 0.283951    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | professional_accounting             | 0.241135    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | professional_law                    | 0.237288    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | professional_medicine               | 0.231618    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | professional_psychology             | 0.271242    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | security_studies                    | 0.183673    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | college_computer_science            | 0.14        |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | astronomy                           | 0.276316    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | college_biology                     | 0.333333    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | medical_genetics                    | 0.31        |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | miscellaneous                       | 0.266922    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | moral_disputes                      | 0.228324    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | moral_scenarios                     | 0.244693    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | nutrition                           | 0.27451     |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | philosophy                          | 0.254019    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | marketing                           | 0.260684    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | prehistory                          | 0.256173    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | professional_law                    | 0.249022    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | professional_medicine               | 0.198529    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | professional_psychology             | 0.227124    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | public_relations                    | 0.327273    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | security_studies                    | 0.2         |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | sociology                           | 0.243781    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | professional_accounting             | 0.251773    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | management                          | 0.174757    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | machine_learning                    | 0.294643    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | logical_fallacies                   | 0.220859    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_european_history        | 0.224242    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_geography               | 0.171717    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_government_and_politics | 0.202073    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_macroeconomics          | 0.233333    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_mathematics             | 0.244444    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_microeconomics          | 0.231092    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_physics                 | 0.18543     |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_psychology              | 0.227523    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_statistics              | 0.236111    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_us_history              | 0.27451     |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_world_history           | 0.261603    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | human_aging                         | 0.286996    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | human_sexuality                     | 0.236641    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | international_law                   | 0.256198    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | jurisprudence                       | 0.277778    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | us_foreign_policy                   | 0.27        |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | virology                            | 0.253012    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | world_religions                     | 0.321637    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          | bigbench_misconceptions          |                                     | 0.456621    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          | jeopardy                         | Average                             | 0.468929    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | american_history                    | 0.523002    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | literature                          | 0.610204    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | science                             | 0.369748    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | word_origins                        | 0.243836    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | world_history                       | 0.597855    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          | bigbench_qa_wikidata             |                                     | 0.725407    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          | arc_easy                         |                                     | 0.732744    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          | arc_challenge                    |                                     | 0.425768    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          | mmlu                             | Average                             | 0.252628    |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | abstract_algebra                    | 0.29        |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | anatomy                             | 0.22963     |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_chemistry               | 0.20197     |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | business_ethics                     | 0.32        |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | clinical_knowledge                  | 0.25283     |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | anatomy                             | 0.288889    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | college_chemistry                   | 0.34        |                10 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | astronomy                           | 0.223684    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | clinical_knowledge                  | 0.230189    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          | bigbench_movie_recommendation    |                                     | 0.238       |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | high_school_biology                 | 0.241935    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | global_facts                        | 0.2         |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | formal_logic                        | 0.246032    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | elementary_mathematics              | 0.238095    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | electrical_engineering              | 0.275862    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | econometrics                        | 0.289474    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | conceptual_physics                  | 0.27234     |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | computer_security                   | 0.3         |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | college_physics                     | 0.264706    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | college_medicine                    | 0.260116    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | college_mathematics                 | 0.21        |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | college_computer_science            | 0.2         |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | college_chemistry                   | 0.2         |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | college_biology                     | 0.284722    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          |                                  | business_ethics                     | 0.28        |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
| world_knowledge          | jeopardy                         | Average                             | 0.283532    |                 0 | togethercomputer/RedPajama-INCITE-7B-Base |
